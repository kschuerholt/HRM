# Baseline replication experiment
# Attempts to replicate the paper's results with their exact configuration

defaults:
  - /arch: hrm_v1
  - _self_

# Use their exact data path structure
data_path: data/arc-aug-1000

# Training hyperparameters (matching paper)
global_batch_size: 768
epochs: 20000  # Standardized across all experiments
steps_per_epoch: 100    # Required field
eval_interval: 2000       # Every 2000 epochs (original paper setting)
checkpoint_every_eval: false  # Only save final checkpoint

# Learning rates (from paper)
lr: 1e-4
lr_min_ratio: 1.0
lr_warmup_steps: 2000

# Optimizer settings (matching their config)
beta1: 0.9
beta2: 0.95
weight_decay: 0.1
puzzle_emb_weight_decay: 0.1

# Puzzle embedding learning rate (key component)
puzzle_emb_lr: 1e-2

# Data
max_seq_len: 900          # Standard sequence length

# Optimizer
optim:
  name: torch.optim.AdamW
  betas: [0.9, 0.95]
  eps: 1e-8

# Scheduler  
scheduler:
  name: transformers.get_cosine_schedule_with_warmup
  num_warmup_steps: 2000
  num_training_steps: 5000000  # epochs * steps_per_epoch

# Logging and monitoring
run_name: baseline_replication
wandb:
  project: hrm_experiments
  name: baseline_replication
  
# Output
output_dir: outputs/baseline_replication

# Evaluation settings
eval_split_names: ["test"]
return_keys: ["q_halt_logits", "q_continue_logits"]  # For ACT analysis

# Experiment specific
seed: 42